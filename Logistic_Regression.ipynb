{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mathematics of Machine Learning\n",
    "\n",
    "## Workbook 3: Logistic Regression & Naive Bayes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different functions we can work with \n",
    "\n",
    "*Logistic Function/Sigmoid Function* $Logit(s) = \\frac{e^s}{1 + e^s}$\n",
    "\n",
    "<img src = 'logistic_plot.png'>\n",
    "\n",
    "*Hyperbolic Tangent* $tanh(s) = \\frac{e^s - e^s}{e^s + e^s}$\n",
    "\n",
    "<img src = 'tanh_plot.png'>\n",
    "\n",
    "Compare those with the plot of a *linear function*\n",
    "<img src = 'linear_plot.png'>\n",
    "\n",
    "#### The Logistic Function and the Hyperbolic Tangent Function are guaranteed to give us values between 0 and 1 no matter our input\n",
    "\n",
    "This helps because we're classifying. What would it mean for an outcome to be 3.5 Pedestrian? We want something like, .87 chance the outcome belongs to class 'Pedestrian.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### P(Outcome  | Data)\n",
    "\n",
    "We interpret outputs as probabilities. Specifically, conditional probabilities. The higher the probability that comes out of our model, the more certain our model is the observation belongs to that class. \n",
    "\n",
    "We hope our model is good enough that a higher probability means it's more likely the observation belongs to that class. \n",
    "\n",
    "This is a **discriminative** learning algorithm. It wants to learn $p(y|x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "\"The standard error measure $e(h(\\vec{x}), y)$ use in logistic regression is based on the notion of *likelihood*; how 'likely' is it that we would get this output *y* from the input $\\vec{x}$ if the target distribution $P(y | \\vec{x})$ was indeed captured by our hypothesis $h(\\vec{x})$?...\n",
    "\n",
    "\"Since the data points $(\\vec{x_1}, y_1),...,(\\vec{x_N}, y_n)$ are independently generated, the probability of getting all the $y_n$'s in the data set from teh corresponding $\\vec{x_n}$'s would be the product\n",
    "$$ \\Pi_{n = 1}^N P(y_n | \\vec{x_n})$$\n",
    "\n",
    "The method of *maximum likelihood* selects the hypothesis *h* which maximizes this probability.\n",
    "\n",
    "-Abu-Mostafa, Magdon-Ismail, Lin, 2012 *Learning from Data: A Short Course*\n",
    "\n",
    "#### But log-liklihoods are easier to work with\n",
    "\n",
    "$$ -\\frac{1}{N} \\ln\\Big(\\Pi_{n=1}^N P(y_n | \\vec{x_n}) \\Big) = \\frac{1}{N} \\Sigma_{n=1}^N ln \\big( \\frac{1}{P(y_n|\\vec{x_n})}\\big)$$\n",
    "\n",
    "#### And we get something to minimizeâ€”how wrong we are\n",
    "\n",
    "$$ Error(\\vec{\\beta}) = \\frac{1}{N} \\Sigma_{n=1}^N \\ln(1 + \\exp(-y_n \\vec{\\beta}^T\\vec{x}_n)) $$\n",
    "\n",
    "This is called Cross-Entropy Error\n",
    "\n",
    "Why does this equation work? Wasn't immediately obvious to me. \n",
    "\n",
    "Say $\\vec{\\beta}^T \\vec{x}_n$ predicts the value is 5, but, in reality, the value of the corresponding y is 0. We get $\\ln(1 + exp(-0 \\cdot 1)) = \\ln(1 + 0) = .69314718056$. \n",
    "\n",
    "If we predict 5 but the value is 1 we get something better: $\\ln(1 + exp(-1 \\cdot 5)) = 0.00671534848$, which is much smaller. \n",
    "\n",
    "In between, we might get 2.5, where the value is 1 and have $\\ln(1 + exp(-1 \\cdot 2.5)) = 0.07888973429$. \n",
    "\n",
    "We reward accuracy *and* confidence. \n",
    "\n",
    "We don't necessarily care about this *per se* we really care about minimizing this, and the gradient of this function\n",
    "\n",
    "$$ \\vec{g}_t =\\nabla Error(\\vec{\\beta}_t) = -\\frac{1}{N} \\Sigma_{n=1}^N \\frac{y_n \\vec{x}_n}{1 + exp(y_n \\vec{\\beta}^T(t)\\vec{x}_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Decent Algorithm with a fixed learning rate $\\eta$\n",
    "\n",
    "1: Initialize weights $\\vec{\\beta}$ = $\\vec{0}$ (aka, guess that everything is zero.)\n",
    "\n",
    "2: Compute gradient $\\vec{g_t} = \\nabla Error(\\vec{\\beta}(t))$ \n",
    "\n",
    "3: Decide what direction to move: $\\vec{v}_t = -\\vec{g}_t$ \n",
    "\n",
    "4: Update the weights: $\\beta(t + 1) = \\beta(t) + \\eta \\vec{v}_t$ $\\leftarrow$ The Number of iterations to convergence depends on the learning rate\n",
    "\n",
    "5: Go back and redo steps 2 through steps 4 until convergence or conk-out\n",
    "\n",
    "<img src = 'gradient_descent.png'>\n",
    "*Blatently Stolen from Wikipedia. Created by: Oleg Alexandrov*\n",
    "*Availible At*: https://commons.wikimedia.org/wiki/File:Gradient_descent.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "\n",
    "Based on Bayes Rule\n",
    "\n",
    "$P(Y = y| X = x) = \\frac{p(x|y)\\cdot p(y)}{p(x)}$\n",
    "\n",
    "**Generative** learning algorithm. The algorithm wants to *model* $p(Y = y| X = x)$ and $p(Y = y)$\n",
    "\n",
    "Assumes that all predictors are conditionally independent from each other $\\leftarrow$ almost never true\n",
    "\n",
    "In practice we almost never calculate the denominator for this since it's the same in both cases. We care about the class so we'll select $max\\{P(Y = A | X = x), P(Y = B | X= X)\\}$ $\\leftarrow$ Which class is more likely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Probability\n",
    "\n",
    "$p(A)$ is the proportion of observations in the data set that belong to class A. $p(B)$ is the proportion of observations that belong to class B. Etc. \n",
    "\n",
    "### Liklihoods \n",
    "\n",
    "Three ways to model the data: Bernoulli, Multinomial, Gaussian \n",
    "\n",
    "Bernoulli: $P(x_i |y) = P(i | y) \\cdot x_i + (1 - P(i|y))(1-x_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_success_given_success = float(sum((data[:, col] == success) and (outcomes == success)))/sum(outcomes == success)\n",
    "\n",
    "\n",
    "p_success_given_fail = float(sum((data[:, col] == success) and (outcomes != success)))/sum(outcomes != success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian: $P(x_i | y) = \\frac{1}{\\sqrt{2\\pi\\sigma_y^2}} exp\\big(-\\frac{(x_i - \\mu_y)^2}{2\\sigma_y^2} \\big)$\n",
    "\n",
    "<img src = 'gaussian_plot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial \n",
    "\n",
    "Could estimate the same way that we estimate the Bernoulli classifer.\n",
    "\n",
    "How many times does $X_1 = 3$ when $Y = A$? How many times does $X_1 = 5$ when $Y = A$?\n",
    "\n",
    "But what happens when we train a data set with where $X_1 \\in (1, 2, 3, 4, 6, 7)$ when $Y = A$ and in the test data $X_1 = 5$? The computed probability for class A would be zero no matter how strong the the rest of the evidence was. \n",
    "\n",
    "We can use $\\alpha$ as a smoothing parameter. \n",
    "\n",
    "$ \\hat{\\theta} = \\frac{N_{yi} + \\alpha}{N_y + \\alpha n}$ where $N_{yi}$ is the number of times the feature appears in the training data for outcome $y$ and $N_{y}$ is the total feature count for the class y. \n",
    "\n",
    "If we set $\\alpha = 0$ we get a straight proportion. Making $\\alpha \\ne 0$ ensures that our model can deal with discrete values it never saw before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weakness with out-of-the-box Naive Bayes classifiers: It will assume one data type for all the variables. If values are continuous and we use a Bernoulli Naive Bayes we need to find a place to split the values $\\rightarrow$ what threshhold gives us a $0$ and what threshold gives us a $1$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Actual Classifier for Class A and Class B:\n",
    "\n",
    "$p(Y = A | X = x) = p(A) \\cdot p(X_1 = x_1 | A) \\cdot p(X_2 = x_2 | A) \\cdot ... \\cdot p(X_n = x_n | A)$\n",
    "\n",
    "$p(Y = B | X = x) = p(B) \\cdot p(X_1 = x_1 | B) \\cdot p(X_2 = x_2 | B) \\cdot ... \\cdot p(X_n = x_n | B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the variables are likely to be correlated, the probabilities tend towards 0 or 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources & Further Reading:\n",
    "\n",
    "Abu-Mostafa, Magdon-Ismail, Lin *Learning From Data*\n",
    "\n",
    "Ng \"On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes\"\n",
    "\n",
    "Scikit-Learn documentation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
